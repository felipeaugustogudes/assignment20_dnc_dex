{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_20_rid2031_felipe.ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFCstNfyy-Vg"
      },
      "source": [
        "# 1. Contextualizado o Problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMrNoqbTzESk"
      },
      "source": [
        "## 1.1 Contexto Geral\n",
        "\n",
        "- O CEO da Amazon contratou um time de cientistas de dados para trabalhar em diferentes vertentes da empresa, e você ficou encarregado de fazer um sistema de recomendação para os clientes Amazon. Para isso, te deram acesso à uma base de dados não muito estruturada em Json: um arquivo de metadata com informações dos produtos e outro com as avaliações.\n",
        "\n",
        "- O CEO deseja que seu algoritmo de recomendação seja exclusivamente em cima de avaliações verificadas (campo `verified`=True no arquivo de avaliações). Contudo, há uma base sem classificação e que o CEO faz questão de que seja\n",
        "adicionada no sistema de recomendação (valores com missing value na coluna `verified`). \n",
        "\n",
        "- Para isso, você precisará classificar se estas avaliações são verificadas ou não, e no caso positivo, adicioná-los no sistema de recomendação.\n",
        "\n",
        "- Adicionalmente, o CEO tam bém deseja saber de possíveis associações e/ou correlações nesta base de dados que você vai trabalhar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da0lWISGzkDY"
      },
      "source": [
        "## 1.2 Objetivos\n",
        "\n",
        "- Carregar, limpar e fazer análises exploratórias no banco de dados fornecido;\n",
        "\n",
        "- Classificar a base sem informação para incluir as observações das avaliações verificadas no sistema de recomendação;\n",
        "\n",
        "- Desenvolver e entregar um sistema de recomendação, com exemplos de aplicação.\n",
        "\n",
        "- O desenvolvimento e a decisão do modelo é totalmente sua, portanto se achar que deve utilizar um valor/ procedimento diferente, sinta-se livre para fazer os testes e validar suas hipóteses para achar o resultado coerente.\n",
        "\n",
        "- LIMPEZA DOS DADOS: Aqui você deve limpar e explorar os dados para decidir variáveis que possam ser úteis para classificação de avaliações verificadas. Você também deve levantar associações e/ou correlação para apresentar ao CEO\n",
        "\n",
        "\n",
        "- EDA Realize uma EDA da forma como preferir, explore os dados, levante ideias, avalie correlações.\n",
        "\n",
        "  - 1° ETAPA CLASSIFICAÇÃO: Aqui você deve utilizar as variáveis estudadas na primeira parte para classificar as avaliações sem label. Deve-se avaliar os modelos criados, tunar ao menos um modelo selecionado e utilizá-lo na classificação. Após classificação, não se esqueça de remover as avaliações\n",
        "não verificadas.\n",
        "\n",
        "  - 2° ETAPA RECOMENDAÇÃO: Aqui você deve desenvolver um sistema de recomendação e mostrá-lo na prática para o CEO. Tente prever possíveis erros\n",
        "para evitá-los de antemão. Por exemplo, caso o produto requisitado não esteja na matriz/base, aponte os 10 mais vendidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oNsc5Yo0MjG"
      },
      "source": [
        "# 2. Pacotes Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RixZfb720kAq"
      },
      "source": [
        "# Bibliotecas Gerais\n",
        "import numpy                   as np\n",
        "import pandas                  as pd\n",
        "import matplotlib.pyplot       as plt\n",
        "import seaborn                 as sns\n",
        "import sys\n",
        "import time\n",
        "from scipy                     import stats\n",
        "\n",
        "# Bibliotecas do Colab\n",
        "from google.colab              import drive\n",
        "\n",
        "# Bibliotecas Classificação\n",
        "from sklearn                       import metrics\n",
        "from sklearn.preprocessing         import MinMaxScaler\n",
        "from sklearn.neighbors             import KNeighborsClassifier\n",
        "from sklearn.linear_model          import LogisticRegression\n",
        "from sklearn.tree                  import DecisionTreeClassifier\n",
        "from sklearn.ensemble              import RandomForestClassifier\n",
        "from sklearn.naive_bayes           import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
        "from sklearn.svm                   import SVC\n",
        "from sklearn.neural_network        import MLPClassifier\n",
        "from sklearn.metrics               import accuracy_score, precision_score, f1_score, recall_score\n",
        "from sklearn.metrics               import classification_report\n",
        "from sklearn.metrics               import plot_confusion_matrix\n",
        "from sklearn.metrics               import plot_roc_curve\n",
        "\n",
        "# Bibliotecas de Recomendação\n",
        "from sklearn.metrics.pairwise      import cosine_similarity\n",
        "\n",
        "# Redução de Dimensionalidade\n",
        "from sklearn.decomposition         import PCA\n",
        "from sklearn.decomposition         import TruncatedSVD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39yrV4dk0O-o"
      },
      "source": [
        "# 3. Leitura de Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v7AoKbC1hRi"
      },
      "source": [
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI6Qs6d71hql"
      },
      "source": [
        "pip freeze --local > /content/gdrive/MyDrive/Colab Notebooks/Super Chellenge/requeriments.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz-Cjded1ktd"
      },
      "source": [
        "link  = '/content/gdrive/MyDrive/Colab Notebooks/Slot7-Assignment/01QualidadeMatPrima.csv'\n",
        "df     = pd.read_csv(link,sep=\";\",decimal=',')\n",
        "df1_save = df1.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Hhaxw90bC9"
      },
      "source": [
        "# 4. EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2zAzDhn1-Ro"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLOuwUgo1-XV"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Jcq4Twy6jf"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6tUlizf2Dy0"
      },
      "source": [
        "pd.DataFrame(df.isnull().sum(axis=0)).sort_values(by=0, ascending=False)/df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb46UGJi1uLW"
      },
      "source": [
        "plt.figure(figsize=(20,12))\n",
        "sns.heatmap(df.corr(), annot=True,cmap='BrBG')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-tS-b_-1xA5"
      },
      "source": [
        "corr_matrix = df.corr()\n",
        "corr_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21ofv9-41yTS"
      },
      "source": [
        "colunas = df.select_dtypes(include='number').columns\n",
        "ncolunas = len(colunas)\n",
        "\n",
        "for i in range(0,ncolunas):\n",
        "  plt.figure(figsize=(20,20))\n",
        "  sns.displot(x=colunas[i],data=df)\n",
        "  plt.show()\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwmLITBh2O-9"
      },
      "source": [
        "# 5. Classificador  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCE3FWzr2OWI"
      },
      "source": [
        "X = df.drop(columns=[\"target\"])\n",
        "Y = df[\"target\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYWmLRlE2T9G"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n",
        "print(f\"Shape X_train: {X_train.shape}\")\n",
        "print(f\"Shape y_train: {y_train.shape}\")\n",
        "print(f\"Shape X_test: {X_test.shape}\")\n",
        "print(f\"Shape y_test: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aErU2Vaj2Vcn"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train = pd.DataFrame(X_train_scaled,columns = X_train.columns)\n",
        "X_test = pd.DataFrame(X_test_scaled,columns = X_test.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj1liSCR2XtX"
      },
      "source": [
        "scores_list = []\n",
        "K_neighbors = range(1,20)\n",
        "\n",
        "for k in K_neighbors:\n",
        "\n",
        "  knn =  KNeighborsClassifier(n_neighbors=k)\n",
        "  knn.fit(X_train, y_train)\n",
        "  y_pred = knn.predict(X_test)\n",
        "  scores_list.append(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDJus8Tv2aQO"
      },
      "source": [
        "plt.plot(K_neighbors, scores_list)\n",
        "plt.xlabel(\"Valor de K\")\n",
        "plt.ylabel(\"Acurácia\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc4Ua2RV2b62"
      },
      "source": [
        "models = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'LogisticRegression': LogisticRegression(),\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(criterion=\"entropy\"),\n",
        "    'RandomForestClassifier': RandomForestClassifier(criterion='entropy', n_estimators=150),\n",
        "    'GaussianNB': GaussianNB(),\n",
        "    'MultinomialNB': MultinomialNB(),\n",
        "    'ComplementNB': ComplementNB(),\n",
        "    'BernoulliNB': BernoulliNB(),\n",
        "    'SVC_Poly': SVC(kernel='poly'),\n",
        "    'SVC_Linear': SVC(kernel='linear'),\n",
        "    'KNeighborsClassifier': KNeighborsClassifier(n_neighbors=5),\n",
        "    'MLPClassifier': MLPClassifier(hidden_layer_sizes=(100, 50, 20),activation='relu'),\n",
        " }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVHFz5yw2ds5"
      },
      "source": [
        "f1score_list    = []\n",
        "clf_list        = []\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "  clf = model\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  f1score   = np.mean(f1_score(y_test, y_pred,average=None))*100\n",
        "  f1score_list.append(f1score)\n",
        "  \n",
        "  clf_list.append(name)\n",
        "  \n",
        "  print(name)\n",
        "  print(f\"F1: {f1score}%\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "\n",
        "  plot_confusion_matrix(clf, X_test, y_test, display_labels=list_classes, values_format='d')\n",
        "  plt.grid(False)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfFiM8R-2grJ"
      },
      "source": [
        "df_metricas = pd.DataFrame({'Classificador': clf_list, 'F1-Score': f1score_list})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVbuFGDK2im6"
      },
      "source": [
        "df_metricas.sort_values(by='F1-Score', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}